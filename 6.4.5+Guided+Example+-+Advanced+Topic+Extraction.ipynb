{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing LSA, LDA, and NNMF\n",
    "\n",
    "Now that you've been introduced to the logic behind these three topic extraction methods, we're going to try them out on the *Emma* corpus.  We'll be looking at interpretability, speed, and consistency across methods.  The goal is to identify common themes in *Emma* on a per-paragraph basis.  We won't be using pLSA as sklearn does not support it.\n",
    "\n",
    "To do this, we will:\n",
    "\n",
    "1. Parse and process the data into a tf-idf matrix.\n",
    "2. Fit LSA, LDA, and NNMF models with 5 topics each.\n",
    "4. Extract the words that best describe each topic.\n",
    "5. Examine the topic relationships for the words 'marriage', 'love', and 'Emma.'\n",
    "\n",
    "## Generating the tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the data.\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#reading in the data, this time in the form of paragraphs\n",
    "emma=gutenberg.paras('austen-emma.txt')\n",
    "#processing\n",
    "emma_paras=[]\n",
    "for paragraph in emma:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    emma_paras.append(' '.join(para))\n",
    "\n",
    "# Creating the tf-idf matrix.\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "emma_paras_tfidf=vectorizer.fit_transform(emma_paras)\n",
    "\n",
    "# Getting the word list.\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# Number of topics.\n",
    "ntopics=5\n",
    "\n",
    "# Linking words to topics\n",
    "def word_topic(tfidf,solution, wordlist):\n",
    "    \n",
    "    # Loading scores for each word on each topic/component.\n",
    "    words_by_topic=tfidf.T * solution\n",
    "\n",
    "    # Linking the loadings to the words in an easy-to-read way.\n",
    "    components=pd.DataFrame(words_by_topic,index=wordlist)\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Extracts the top N words and their loadings for each topic.\n",
    "def top_words(components, n_top_words):\n",
    "    n_topics = range(components.shape[1])\n",
    "    index= np.repeat(n_topics, n_top_words, axis=0)\n",
    "    topwords=pd.Series(index=index)\n",
    "    for column in range(components.shape[1]):\n",
    "        # Sort the column so that highest loadings are at the top.\n",
    "        sortedwords=components.iloc[:,column].sort_values(ascending=False)\n",
    "        # Choose the N highest loadings.\n",
    "        chosen=sortedwords[:n_top_words]\n",
    "        # Combine loading and index into a string.\n",
    "        chosenlist=chosen.index +\" \"+round(chosen,2).map(str) \n",
    "        topwords.loc[column]=chosenlist\n",
    "    return(topwords)\n",
    "\n",
    "# Number of words to look at for each topic.\n",
    "n_top_words = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to creating the tfidf matrix, there are two convenience functions that will help keep the code tidy when comparing models.  The first provides a list of the words that are paired with each topic.  The second gives us the best words for each topic so we can compare across methods.\n",
    "\n",
    "## Fitting the three topic extraction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "emma_paras_lsa = lsa.fit_transform(emma_paras_tfidf)\n",
    "\n",
    "components_lsa = word_topic(emma_paras_tfidf, emma_paras_lsa, terms)\n",
    "\n",
    "topwords=pd.DataFrame()\n",
    "topwords['LSA']=top_words(components_lsa, n_top_words)                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA(n_topics=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "emma_paras_lda = lda.fit_transform(emma_paras_tfidf) \n",
    "\n",
    "components_lda = word_topic(emma_paras_tfidf, emma_paras_lda, terms)\n",
    "\n",
    "topwords['LDA']=top_words(components_lda, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "emma_paras_nmf = nmf.fit_transform(emma_paras_tfidf) \n",
    "\n",
    "components_nmf = word_topic(emma_paras_tfidf, emma_paras_nmf, terms)\n",
    "\n",
    "topwords['NNMF']=top_words(components_nmf, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are mostly using the default settings for each method, but explicitly printing them so it is clear what is going on and how each model can be modified.  sklearn has such nice parallel structure for its various topic extraction methods that we could probably have abstracted the code even further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the topics\n",
    "\n",
    "For each topic, we list the ten most-relevant words according to each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "               LSA              LDA             NNMF\n",
      "0         oh 97.61         mr 51.99         oh 30.12\n",
      "0         yes 4.82       emma 49.89         yes 0.52\n",
      "0       thank 1.58       said 39.52       sorry 0.16\n",
      "0  difference 1.56        mrs 35.23  difference 0.15\n",
      "0        just 1.44       miss 29.94        just 0.12\n",
      "0     harriet 1.32    harriet 26.28        papa 0.12\n",
      "0       sorry 1.28     weston 25.61        week 0.11\n",
      "0       short 1.17  knightley 24.56       short 0.11\n",
      "0        papa 1.15      elton 23.59    recollect 0.1\n",
      "0   recollect 1.02        did 20.92      letter 0.09\n",
      "Topic 1:\n",
      "             LSA           LDA            NNMF\n",
      "1     emma 58.27      oh 56.84         mr 7.29\n",
      "1       mr 58.08      ah 18.12        mrs 4.26\n",
      "1     said 50.66     emma 6.46      elton 3.41\n",
      "1      mrs 47.07     said 4.87  knightley 3.24\n",
      "1     miss 37.33   harriet 4.7     weston 3.15\n",
      "1  harriet 34.77       mr 4.68       miss 2.99\n",
      "1   weston 32.23  chapter 4.14  woodhouse 2.09\n",
      "1    elton 27.76      mrs 3.17       said 1.88\n",
      "1      did 27.59     miss 3.14    fairfax 1.84\n",
      "1    think 26.81    think 3.03       emma 1.47\n",
      "Topic 2:\n",
      "             LSA            LDA           NNMF\n",
      "2       ah 31.15  chapter 20.22       ah 12.89\n",
      "2      sure 3.76       oh 10.15      sure 0.35\n",
      "2       say 1.38        yes 8.9   believe 0.18\n",
      "2     thank 1.25      sure 6.93       say 0.18\n",
      "2   believe 0.84      emma 6.87     shake 0.09\n",
      "2      sorry 0.8      dear 6.25     hands 0.09\n",
      "2     finis 0.69        mr 6.07     sorry 0.09\n",
      "2     shake 0.49      true 5.51  grievous 0.08\n",
      "2     hands 0.49     thank 5.47      come 0.07\n",
      "2  grievous 0.44      said 5.19    taylor 0.07\n",
      "Topic 3:\n",
      "             LSA           LDA           NNMF\n",
      "3  chapter 33.91       oh 9.59  chapter 10.46\n",
      "3         ii 3.2     emma 5.75       iii 0.68\n",
      "3        iii 3.2     good 4.13        ii 0.68\n",
      "3        xv 2.52       mr 4.12       vii 0.66\n",
      "3        vi 2.52     said 3.91        xv 0.66\n",
      "3        iv 2.52     read 3.34       xvi 0.66\n",
      "3      xvii 2.52      mrs 3.19      xvii 0.66\n",
      "3       xiv 2.52    think 3.15     xviii 0.66\n",
      "3      viii 2.52       ah 3.06       xii 0.66\n",
      "3       xii 2.52  chapter 2.99        xi 0.66\n",
      "Topic 4:\n",
      "               LSA           LDA          NNMF\n",
      "4         mr 38.17       oh 9.68     emma 9.27\n",
      "4  knightley 18.88     emma 8.16     said 5.84\n",
      "4      elton 15.25     said 5.82     dear 3.52\n",
      "4      weston 9.48       mr 5.61  harriet 2.89\n",
      "4         mrs 6.65    shall 4.82      yes 2.29\n",
      "4        john 4.49  harriet 4.52    think 1.74\n",
      "4      martin 3.18      mrs 4.32       mr 1.69\n",
      "4    woodhouse 2.6     dear 4.28      say 1.52\n",
      "4        idea 1.88     papa 3.53    thing 1.32\n",
      "4        plan 1.65       ah 3.05     sure 1.27\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords.loc[topic])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of things are clear.  First, some topics are shared, though the order of topics varies- the 'oh' topic is first for LSA and NNMF, but second for LDA.  And second, the content of some of the topics varies considerably across methods.  This is a clear argument for using multiple methods when exploring topics.\n",
    "\n",
    "# Sparsity\n",
    "\n",
    "Now let's examine sparsity by looking at the distributions of loadings for the words 'marriage', 'love', 'emma', and 'oh' across the methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The words to look at.\n",
    "targetwords=['marriage','love','emma','oh']\n",
    "\n",
    "# Storing the loadings.\n",
    "wordloadings=pd.DataFrame(columns=targetwords)\n",
    "\n",
    "# For each word, extracting and string the loadings for each method.\n",
    "for word in targetwords:\n",
    "    loadings=components_lsa.loc[word].append(\n",
    "        components_lda.loc[word]).append(\n",
    "            components_nmf.loc[word])\n",
    "    wordloadings[word]=loadings\n",
    "\n",
    "# Labeling the data by method and providing an ordering variable for graphing purposes. \n",
    "wordloadings['method']=np.repeat(['LSA','LDA','NNMF'], 5, axis=0)\n",
    "wordloadings['loading']=[0,1,2,3,4]*3\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "for word in targetwords:\n",
    "    sns.barplot(x=\"method\", y=word, hue=\"loading\", data=wordloadings)\n",
    "    plt.title(word)\n",
    "    plt.ylabel(\"\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA is the method most likely to have high loadings on more than one topic for the same word.  LDA tends to have one high loading and some lower loadings.  Loadings for NNMF are lower all around, and the most sparse, with some of the topics having loadings of zero on each word.\n",
    "\n",
    "# Challenge: Topic extraction on new data\n",
    "\n",
    "Take the well-known [20 newsgroups](http://qwone.com/~jason/20Newsgroups/) dataset and use each of the methods on it.  Your goal is to determine which method, if any, best reproduces the topics represented by the newsgroups.  Write up a report where you evaluate each method in light of the 'ground truth'- the known source of each newsgroup post.  Which works best, and why do you think this is the case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "    print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['rec.autos','rec.sport.hockey','sci.med','talk.politics.mideast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newsgroups Used ###\n",
    "\n",
    "* Let's concentrate on four newsgroups\n",
    "    * Rec.Autos\n",
    "    * Rec.sport.hockey\n",
    "    * Sci.med\n",
    "    * Talk.politics.mideast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_auto = fetch_20newsgroups(subset='train',\n",
    "                             remove=('headers', 'footers', 'quotes'),\n",
    "                             categories=['rec.autos'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_hockey = fetch_20newsgroups(subset='train',\n",
    "                               remove=('headers', 'footers', 'quotes'),\n",
    "                               categories=['rec.sport.hockey'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_med =    fetch_20newsgroups(subset='train',\n",
    "                               remove=('headers', 'footers', 'quotes'),\n",
    "                               categories=[groups[2]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_mideast = fetch_20newsgroups(subset='train',\n",
    "                                remove=('headers', 'footers', 'quotes'),\n",
    "                                categories=[groups[3]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer(stop_words='english')\n",
    "vector_auto = vectorizer1.fit_transform(ng_auto.data)\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(stop_words='english')\n",
    "vector_hockey = vectorizer2.fit_transform(ng_hockey.data)\n",
    "\n",
    "vectorizer3 = TfidfVectorizer(stop_words='english')\n",
    "vector_med = vectorizer3.fit_transform(ng_med.data)\n",
    "\n",
    "vectorizer4 = TfidfVectorizer(stop_words='english')\n",
    "vector_mideast = vectorizer4.fit_transform(ng_mideast.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Models ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rec.autos ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LSA\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "autos_lsa = lsa.fit_transform(vector_auto)\n",
    "\n",
    "# Getting the word list.\n",
    "terms = vectorizer1.get_feature_names()\n",
    "\n",
    "auto_components_lsa = word_topic(vector_auto, autos_lsa, terms)\n",
    "\n",
    "topwords_auto=pd.DataFrame()\n",
    "topwords_auto['LSA']=top_words(auto_components_lsa, n_top_words)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# using LDA\n",
    "\n",
    "lda = LDA(n_topics=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "autos_lda = lda.fit_transform(vector_auto) \n",
    "\n",
    "components_lda = word_topic(vector_auto, autos_lda, terms)\n",
    "\n",
    "topwords_auto['LDA']=top_words(components_lda, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NNMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "autos_nmf = nmf.fit_transform(vector_auto) \n",
    "\n",
    "components_nmf = word_topic(vector_auto, autos_nmf, terms)\n",
    "\n",
    "topwords_auto['NNMF']=top_words(components_nmf, n_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Topics in Rec.autos ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "          LSA               LDA        NNMF\n",
      "0   car 15.88         ites 0.98  speed 0.57\n",
      "0    like 9.5          car 0.77    car 0.55\n",
      "0    just 8.5      archive 0.48  drive 0.49\n",
      "0   cars 7.73  continental 0.48   cars 0.47\n",
      "0   good 7.01           gt 0.46   just 0.47\n",
      "0    new 6.99         like 0.45  right 0.43\n",
      "0    know 6.5          ibm 0.39    like 0.4\n",
      "0    don 6.47          5sp 0.39    road 0.4\n",
      "0  think 5.63       server 0.38   auto 0.39\n",
      "0   does 5.16        catch 0.38    sho 0.36\n",
      "Topic 1:\n",
      "               LSA           LDA                NNMF\n",
      "1          __ 3.28       __ 1.74             __ 2.08\n",
      "1       _____ 1.28  deleted 1.06          _____ 0.82\n",
      "1         ___ 1.23    stuff 0.94            ___ 0.74\n",
      "1        ____ 0.86    _____ 0.69        _______ 0.55\n",
      "1     _______ 0.85      ___ 0.62           ____ 0.52\n",
      "1      wouldn 0.73      car 0.62            16v 0.27\n",
      "1  understand 0.55     ditto 0.6             oo 0.27\n",
      "1        need 0.54      like 0.5           ncsl 0.27\n",
      "1         keys 0.5  _______ 0.46  fahrvergnugen 0.27\n",
      "1    probably 0.48     hear 0.43         ______ 0.27\n",
      "Topic 2:\n",
      "              LSA          LDA          NNMF\n",
      "2        car 3.76    car 17.32      car 2.32\n",
      "2     dealer 3.29    like 9.98      new 0.88\n",
      "2      price 2.66    just 9.58   dealer 0.88\n",
      "2     saturn 1.92    cars 8.58    price 0.82\n",
      "2     thanks 1.71    good 7.52      like 0.8\n",
      "2        new 1.57     new 7.49     good 0.67\n",
      "2      prices 1.4     don 7.25     cars 0.58\n",
      "2  insurance 1.11    know 7.18   thanks 0.57\n",
      "2      bought 1.0   think 6.47   saturn 0.56\n",
      "2     looking 0.9  engine 6.31  looking 0.51\n",
      "Topic 3:\n",
      "           LSA          LDA          NNMF\n",
      "3  engine 3.42     car 0.62   engine 1.15\n",
      "3     oil 3.04    just 0.38      oil 1.09\n",
      "3     new 1.31    like 0.37      car 0.57\n",
      "3   miles 1.21    know 0.29   change 0.42\n",
      "3   tires 1.19    cars 0.29      like 0.4\n",
      "3   drain 1.18     new 0.29      gas 0.38\n",
      "3    ford 1.16    good 0.28  problem 0.38\n",
      "3    plug 1.12  thanks 0.24    miles 0.36\n",
      "3  problem 1.1     don 0.24     time 0.34\n",
      "3    used 1.09  dealer 0.24     plug 0.32\n",
      "Topic 4:\n",
      "            LSA                LDA        NNMF\n",
      "4     just 2.71         bored 0.73   just 0.95\n",
      "4     ford 1.83  _incredibly_ 0.73  people 0.9\n",
      "4     know 1.77           car 0.63    don 0.65\n",
      "4      oil 1.72       reading 0.62  think 0.62\n",
      "4  problem 1.72          book 0.59   know 0.62\n",
      "4   dealer 1.43         phone 0.58   like 0.51\n",
      "4       don 1.4    considered 0.57     car 0.5\n",
      "4      did 1.24      appeared 0.52    ford 0.5\n",
      "4    wanted 1.1         today 0.46    did 0.45\n",
      "4   people 1.06        hahaha 0.43   life 0.45\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords_auto.loc[topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rec.sport.hockey ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(stop_words='english')\n",
    "vector_hockey = vectorizer2.fit_transform(ng_hockey.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LSA\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "hockey_lsa = lsa.fit_transform(vector_hockey)\n",
    "\n",
    "# Getting the word list.\n",
    "terms2 = vectorizer2.get_feature_names()\n",
    "\n",
    "hockey_components_lsa = word_topic(vector_hockey, hockey_lsa, terms2)\n",
    "\n",
    "topwords_hockey=pd.DataFrame()\n",
    "topwords_hockey['LSA']=top_words(hockey_components_lsa, n_top_words)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# using LDA\n",
    "\n",
    "lda = LDA(n_topics=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "hockey_lda = lda.fit_transform(vector_hockey) \n",
    "\n",
    "hockey_components_lda = word_topic(vector_hockey, hockey_lda, terms2)\n",
    "\n",
    "topwords_hockey['LDA']=top_words(hockey_components_lda, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NNMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "hockey_nmf = nmf.fit_transform(vector_hockey) \n",
    "\n",
    "components_nmf = word_topic(vector_hockey, hockey_nmf, terms2)\n",
    "\n",
    "topwords_hockey['NNMF']=top_words(components_nmf, n_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Topics in Rec.sport.hockey ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "           LSA             LDA          NNMF\n",
      "0   game 12.75      rectum 0.6     game 1.26\n",
      "0   team 11.46       game 0.48     team 1.14\n",
      "0  hockey 9.74     assume 0.44   hockey 1.03\n",
      "0   games 8.67  sarcastic 0.42  players 0.98\n",
      "0     don 8.41       team 0.41   season 0.85\n",
      "0   think 8.24     remark 0.41      don 0.81\n",
      "0  season 8.24      vielen 0.4    think 0.79\n",
      "0    play 8.14        dank 0.4     play 0.77\n",
      "0    year 7.97        just 0.4    games 0.76\n",
      "0    just 7.95  desperate 0.38     like 0.76\n",
      "Topic 1:\n",
      "           LSA           LDA         NNMF\n",
      "1  period 3.02   colons 0.48  period 1.33\n",
      "1      10 2.98     game 0.48      10 1.12\n",
      "1     pts 2.77  florida 0.39      pp 1.04\n",
      "1      11 2.77     team 0.38      11 1.01\n",
      "1      pp 2.35    south 0.37     pts 0.92\n",
      "1      12 2.22   hockey 0.37      12 0.81\n",
      "1      55 2.02     just 0.36   power 0.76\n",
      "1      18 1.84    games 0.32  scorer 0.68\n",
      "1      19 1.75     like 0.31      18 0.66\n",
      "1      15 1.71    think 0.31    play 0.62\n",
      "Topic 2:\n",
      "            LSA           LDA          NNMF\n",
      "2      let 3.88    game 14.18      let 1.57\n",
      "2      edu 2.76    team 12.17      sas 0.97\n",
      "2     mail 2.58  hockey 10.53  quakers 0.97\n",
      "2    upenn 2.02      don 9.01  kkeller 0.97\n",
      "2  kkeller 2.02    think 8.95      ivy 0.97\n",
      "2   keller 2.02    games 8.94   keller 0.97\n",
      "2      ivy 2.02  players 8.84    upenn 0.97\n",
      "2  quakers 2.02   season 8.64   champs 0.93\n",
      "2      sas 2.02     play 8.61     mail 0.93\n",
      "2   champs 1.92     year 8.44      edu 0.92\n",
      "Topic 3:\n",
      "            LSA          LDA             NNMF\n",
      "3  detroit 2.97      10 2.43     detroit 1.09\n",
      "3    hawks 2.87      11 1.96          vs 1.07\n",
      "3       vs 2.77       55 1.9     chicago 0.85\n",
      "3     game 2.59  period 1.84     toronto 0.81\n",
      "3     espn 2.22     pts 1.66        game 0.75\n",
      "3      win 2.17       gm 1.6  pittsburgh 0.71\n",
      "3    leafs 1.95      12 1.59    division 0.69\n",
      "3   series 1.77      pp 1.51       hawks 0.68\n",
      "3      cal 1.77      25 1.36         win 0.67\n",
      "3   toronto 1.7      19 1.29      winner 0.67\n",
      "Topic 4:\n",
      "             LSA           LDA             NNMF\n",
      "4        gm 5.39      faq 0.69           gm 2.5\n",
      "4    murray 2.09     test 0.51      murray 0.74\n",
      "4       nhl 1.54     game 0.48       utica 0.43\n",
      "4   players 1.47  message 0.46  adirondack 0.43\n",
      "4         vs 1.3      gak 0.44   baltimore 0.42\n",
      "4      team 1.23     team 0.38   rochester 0.41\n",
      "4     coach 1.11      fun 0.38     moncton 0.39\n",
      "4  senators 0.96   hockey 0.33         cdi 0.37\n",
      "4   moncton 0.94     just 0.32  binghamton 0.36\n",
      "4    traded 0.88    games 0.32          vs 0.35\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords_hockey.loc[topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sci.med ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer3 = TfidfVectorizer(stop_words='english')\n",
    "vector_med = vectorizer3.fit_transform(ng_med.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LSA\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "med_lsa = lsa.fit_transform(vector_med)\n",
    "\n",
    "# Getting the word list.\n",
    "terms3 = vectorizer3.get_feature_names()\n",
    "\n",
    "med_components_lsa = word_topic(vector_med, med_lsa, terms3)\n",
    "\n",
    "topwords_med=pd.DataFrame()\n",
    "topwords_med['LSA']=top_words(med_components_lsa, n_top_words)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# using LDA\n",
    "\n",
    "lda = LDA(n_topics=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "med_lda = lda.fit_transform(vector_med) \n",
    "\n",
    "med_components_lda = word_topic(vector_med, med_lda, terms3)\n",
    "\n",
    "topwords_med['LDA']=top_words(med_components_lda, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NNMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "med_nmf = nmf.fit_transform(vector_med) \n",
    "\n",
    "components_nmf = word_topic(vector_med, med_nmf, terms3)\n",
    "\n",
    "topwords_med['NNMF']=top_words(components_nmf, n_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Topics in Sci.med ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "             LSA               LDA             NNMF\n",
      "0        edu 9.1         know 0.38       cadre 2.03\n",
      "0       geb 8.39      britain 0.35         dsl 2.03\n",
      "0     banks 8.34          edu 0.32    shameful 2.03\n",
      "0      pitt 8.32  information 0.31   surrender 2.03\n",
      "0    gordon 8.25           msg 0.3         geb 2.03\n",
      "0        dsl 8.2          don 0.29       n3jxp 2.03\n",
      "0   shameful 8.2          geb 0.28    chastity 2.03\n",
      "0      cadre 8.2        banks 0.28   intellect 2.03\n",
      "0  surrender 8.2       gordon 0.28  skepticism 2.02\n",
      "0     n3jxp 8.19         pitt 0.28        pitt 2.01\n",
      "Topic 1:\n",
      "           LSA          LDA         NNMF\n",
      "1    know 6.88    know 0.34    pain 1.31\n",
      "1     msg 6.22    like 0.33  doctor 0.89\n",
      "1     don 6.14     edu 0.32  clinic 0.47\n",
      "1  people 6.12   memes 0.32     don 0.37\n",
      "1    like 5.58      msg 0.3    said 0.33\n",
      "1    just 4.96     don 0.29    told 0.33\n",
      "1    does 4.92     geb 0.28   doesn 0.32\n",
      "1    think 4.9   banks 0.28    time 0.28\n",
      "1    food 4.89  gordon 0.28    like 0.27\n",
      "1    time 4.69    pitt 0.28     did 0.26\n",
      "Topic 2:\n",
      "              LSA                LDA            NNMF\n",
      "2        msg 8.02         toxin 0.54        msg 2.91\n",
      "2       food 4.04     aflatoxin 0.44       food 1.57\n",
      "2    chinese 1.98  contaminants 0.44    chinese 0.74\n",
      "2   glutamate 1.3           corn 0.4     people 0.55\n",
      "2     flavor 1.15      expensive 0.4       just 0.45\n",
      "2  restaurant 1.1          know 0.34     flavor 0.43\n",
      "2       carl 1.02           edu 0.32   reaction 0.42\n",
      "2      taste 0.93            msg 0.3  glutamate 0.41\n",
      "2        eat 0.88           don 0.29         don 0.4\n",
      "2   reaction 0.79           geb 0.28        eat 0.39\n",
      "Topic 3:\n",
      "                LSA           LDA              NNMF\n",
      "3      science 3.45  melittin 0.6      science 1.51\n",
      "3   scientific 2.08       tx 0.52   scientific 0.89\n",
      "3  methodology 1.31      don 0.37        think 0.68\n",
      "3        think 1.24   bogota 0.36  methodology 0.58\n",
      "3      rational 1.1   mexico 0.36     thinking 0.45\n",
      "3     thinking 1.05      paz 0.36    empirical 0.41\n",
      "3     evidence 1.01     waco 0.36       studies 0.4\n",
      "3       theory 0.96     know 0.34           don 0.4\n",
      "3     research 0.92     just 0.34        ideas 0.38\n",
      "3      studies 0.88      edu 0.34   psychology 0.35\n",
      "Topic 4:\n",
      "               LSA          LDA           NNMF\n",
      "4     disease 2.97     edu 9.74   disease 0.95\n",
      "4      candida 2.4      msg 9.3      know 0.92\n",
      "4       yeast 2.13     don 9.26    people 0.76\n",
      "4      cancer 1.94    know 8.95  patients 0.74\n",
      "4    patients 1.47  people 8.02   medical 0.69\n",
      "4        body 1.46  gordon 7.66       don 0.67\n",
      "4      people 1.14   banks 7.63      does 0.65\n",
      "4    diseases 1.12    like 7.61    candida 0.6\n",
      "4  information 1.1     geb 7.58      like 0.59\n",
      "4        does 1.08    pitt 7.55     yeast 0.59\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords_med.loc[topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk.politics.mideast ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer4 = TfidfVectorizer(stop_words='english')\n",
    "vector_mideast = vectorizer4.fit_transform(ng_mideast.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LSA\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "mideast_lsa = lsa.fit_transform(vector_mideast)\n",
    "\n",
    "# Getting the word list.\n",
    "terms4 = vectorizer4.get_feature_names()\n",
    "\n",
    "mideast_components_lsa = word_topic(vector_mideast, mideast_lsa, terms4)\n",
    "\n",
    "topwords_mideast=pd.DataFrame()\n",
    "topwords_mideast['LSA']=top_words(mideast_components_lsa, n_top_words)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/ljagged/miniconda3/envs/thinkful/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# using LDA\n",
    "\n",
    "lda = LDA(n_topics=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "mideast_lda = lda.fit_transform(vector_mideast) \n",
    "\n",
    "mideast_components_lda = word_topic(vector_mideast, mideast_lda, terms4)\n",
    "\n",
    "topwords_mideast['LDA']=top_words(mideast_components_lda, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NNMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "mideast_nmf = nmf.fit_transform(vector_mideast) \n",
    "\n",
    "components_nmf = word_topic(vector_mideast, mideast_nmf, terms4)\n",
    "\n",
    "topwords_mideast['NNMF']=top_words(components_nmf, n_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Topics in Talk.politics.mideast ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "              LSA             LDA           NNMF\n",
      "0    israel 12.05      loser 0.52    israel 2.12\n",
      "0     people 9.65    asshole 0.51   israeli 1.26\n",
      "0    israeli 8.59     pollard 0.5      arab 0.85\n",
      "0       jews 8.12     israel 0.48      jews 0.82\n",
      "0   armenian 7.72       jerk 0.45  lebanese 0.62\n",
      "0  armenians 7.09    nursery 0.45     arabs 0.55\n",
      "0       just 6.91     shrink 0.42   lebanon 0.54\n",
      "0    turkish 6.53  definetly 0.42     peace 0.51\n",
      "0       said 6.29        john 0.4  israelis 0.49\n",
      "0       arab 6.26      cases 0.38     state 0.48\n",
      "Topic 1:\n",
      "              LSA               LDA            NNMF\n",
      "1   armenian 6.31      retarded 1.3   armenian 2.48\n",
      "1  armenians 5.22       israel 0.48  armenians 1.69\n",
      "1    turkish 4.67    delightful 0.4    turkish 1.36\n",
      "1    armenia 2.81         just 0.39   genocide 1.19\n",
      "1   genocide 2.74          hey 0.38     people 0.93\n",
      "1     turkey 2.52          did 0.38     soviet 0.87\n",
      "1      turks 2.37  interesting 0.36    armenia 0.81\n",
      "1     serdar 2.13       kindly 0.36    russian 0.73\n",
      "1       argic 1.9        aswer 0.35     muslim 0.72\n",
      "1     soviet 1.87     question 0.33      turks 0.72\n",
      "Topic 2:\n",
      "          LSA             LDA            NNMF\n",
      "2    said 2.8   armenian 6.62       said 1.24\n",
      "2    say 2.52  armenians 4.83     people 1.02\n",
      "2   just 2.36    turkish 3.69       didn 0.87\n",
      "2    don 2.08   genocide 3.33       went 0.81\n",
      "2   didn 2.03     people 3.25  armenians 0.79\n",
      "2   know 1.74     soviet 2.45       know 0.77\n",
      "2  think 1.49     muslim 2.27        don 0.74\n",
      "2   went 1.48      turks 2.12        say 0.71\n",
      "2  loser 1.36     serdar 2.12    sumgait 0.69\n",
      "2  going 1.23    russian 2.08       just 0.68\n",
      "Topic 3:\n",
      "             LSA             LDA          NNMF\n",
      "3    israel 4.05       45th 0.81    greek 1.68\n",
      "3  lebanese 2.38   birthday 0.75  turkish 1.49\n",
      "3   lebanon 2.05     israel 0.74   greece 0.89\n",
      "3   israeli 1.58      happy 0.59   turkey 0.82\n",
      "3  armenian 1.43        ihr 0.49   cyprus 0.81\n",
      "3  civilians 1.2       1760 0.42    turks 0.77\n",
      "3  villages 1.13        280 0.42   greeks 0.69\n",
      "3  soldiers 1.05       anal 0.41    henrik 0.6\n",
      "3   attacks 0.89       wimp 0.41   people 0.49\n",
      "3    killed 0.85  retentive 0.41  armenia 0.44\n",
      "Topic 4:\n",
      "             LSA            LDA           NNMF\n",
      "4      adam 4.27   israel 15.84      adam 2.09\n",
      "4   harvard 1.71  israeli 10.74      jews 0.98\n",
      "4       das 1.54     jews 10.13   harvard 0.76\n",
      "4  shostack 1.53    people 9.16  shostack 0.75\n",
      "4       edu 1.41      just 7.53       das 0.74\n",
      "4  armenian 1.21      arab 7.53       edu 0.69\n",
      "4     loser 0.86       don 6.98    israel 0.45\n",
      "4    arafat 0.81      know 6.32    people 0.32\n",
      "4  lebanese 0.72      said 6.32     arabs 0.31\n",
      "4    bodies 0.53     think 6.18   judaism 0.29\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords_mideast.loc[topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion ##\n",
    "\n",
    "We have taken the 20 Newsgroups dataset in order to further test\n",
    "topic extraction using LSA, LDA, and NNMF. I conduct an investigation\n",
    "into each method by running topic extraction on four of the newsgroups.\n",
    "The selected newsgroups are rec.autos, rec.sport.hockey, sci.med, and\n",
    "talk.politics.mideast. Each of these newsgroups deals with quite separate\n",
    "and highly distinguishable topics.  Rec.autos deals with automotive issues\n",
    "such as car makes and models and driving experiences.  Rec.sports.hockey deals\n",
    "with hockey issues (the teams and specific games) obviously.  Sci.med is a broad\n",
    "based medical newsgroup and the topics should be relating to health issues and\n",
    "diseases and conditions related to human medical matters.  Talk.politics.mideast\n",
    "is a rather self explanatory newsgroup that would most likely to dealing with\n",
    "the countries of the mideast and issues such as wars and confict of that region.\n",
    "\n",
    "The results of topic extraction for rec.auto is informative. Topic 0 from both\n",
    "LSA and NNMF display words like car, cars, road, speed, auto and drive.  NNMF\n",
    "has the most topical with LSA close behind.  LDA contains car but little else.\n",
    "Topic 2 has almost identical results for LSA and NNMF containing more complex\n",
    "issues like insurance, saturn, price and dealer while LDA has only simpler words\n",
    "like cars, engine and new.  The general appearance of the topic in rec.auto\n",
    "appears to be that LSA and NNMF are quite similar and contain a greater variety\n",
    "of complex on-topic automotive ideas and LDA seems to be rather lacking in this regard.\n",
    "\n",
    "This pattern recurs with the rest of the newsgroups in general.  LSA and NNMF\n",
    "generally find keywords that are on target to the ground truth on the newsgroup.  \n",
    "LDA can often find the most obvious high level words such as israel and arab in talk.politics.mideast but often contains garbled or off-topic words or overly \n",
    "elaborate words such contaminants in sci.med that do not hold to a coherent topic.  \n",
    "\n",
    "From the experience using these algorithms, I feel compelled to say that LDA\n",
    "was overall the worst performing algorithm of the three.  It often fixated on\n",
    "strange vocabulary that was almost always off-topic.  NNMF and LSA can both \n",
    "be relied upon to exract keyword topics that make good intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
