{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Text\n",
    "\n",
    "Let's try out extractive summarization using the first four paragraphs of [The Great Gatsby](http://gutenberg.net.au/ebooks02/0200041h.html).\n",
    "\n",
    "First, we'll try to extract the most representative sentence.  Then, we'll extract keywords.\n",
    "\n",
    "## Sentence extraction\n",
    "\n",
    "The steps of our sentence extraction process:\n",
    "\n",
    "1. Parse and tokenize the text using spaCy, and divide into sentences.\n",
    "2. Calculate the tf-idf matrix.\n",
    "3. Calculate similarity scores.\n",
    "4. Calculate TextRank: We're going to use the ´networkx´ package to run the TextRank algorithm.\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the text the lazy way.\n",
    "gatsby=\"In my younger and more vulnerable years my father gave me some advice that Ive been turning over in my mind ever since. \\\"Whenever you feel like criticizing any one,\\\" he told me, \\\"just remember that all the people in this world havent had the advantages that youve had.\\\" He didn't say any more but weve always been unusually communicative in a reserved way, and I understood that he meant a great deal more than that. In consequence Im inclined to reserve all judgments, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores. The abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person, and so it came about that in college I was unjustly accused of being a politician, because I was privy to the secret griefs of wild, unknown men. Most of the confidences were unsought--frequently I have feigned sleep, preoccupation, or a hostile levity when I realized by some unmistakable sign that an intimate revelation was quivering on the horizon--for the intimate revelations of young men or at least the terms in which they express them are usually plagiaristic and marred by obvious suppressions. Reserving judgments is a matter of infinite hope. I am still a little afraid of missing something if I forget that, as my father snobbishly suggested, and I snobbishly repeat a sense of the fundamental decencies is parcelled out unequally at birth. And, after boasting this way of my tolerance, I come to the admission that it has a limit. Conduct may be founded on the hard rock or the wet marshes but after a certain point I dont care what its founded on. When I came back from the East last autumn I felt that I wanted the world to be in uniform and at a sort of moral attention forever; I wanted no more riotous excursions with privileged glimpses into the human heart. Only Gatsby, the man who gives his name to this book, was exempt from my reaction--Gatsby who represented everything for which I have an unaffected scorn. If personality is an unbroken series of successful gestures, then there was something gorgeous about him, some heightened sensitivity to the promises of life, as if he were related to one of those intricate machines that register earthquakes ten thousand miles away. This responsiveness had nothing to do with that flabby impressionability which is dignified under the name of the \\\"creative temperament\\\"--it was an extraordinary gift for hope, a romantic readiness such as I have never found in any other person and which it is not likely I shall ever find again. No--Gatsby turned out all right at the end; it is what preyed on Gatsby, what foul dust floated in the wake of his dreams that temporarily closed out my interest in the abortive sorrows and short-winded elations of men.\"\n",
    "\n",
    "# We want to use the standard english-language parser.\n",
    "# DWS NOTE:  WARNING\n",
    "# Note: I had to run \"spacy download en_core_web_sm\"\n",
    "# then we load 'en_core_web_sm' instead of simply 'en'\n",
    "parser = spacy.load('en_core_web_sm')\n",
    "#parser = spacy.load('en')\n",
    "\n",
    "# Parsing Gatsby.\n",
    "gatsby = parser(gatsby)\n",
    "\n",
    "# Dividing the text into sentences and storing them as a list of strings.\n",
    "sentences=[]\n",
    "for span in gatsby.sents:\n",
    "    # go from the start to the end of each span, returning each token in the sentence\n",
    "    # combine each token using join()\n",
    "    sent = ''.join(gatsby[i].string for i in range(span.start, span.end)).strip()\n",
    "    sentences.append(sent)\n",
    "\n",
    "# Creating the tf-idf matrix.\n",
    "counter = TfidfVectorizer(lowercase=False, \n",
    "                          stop_words=None,\n",
    "                          ngram_range=(1, 1), \n",
    "                          analyzer=u'word', \n",
    "                          max_df=.5, \n",
    "                          min_df=1,\n",
    "                          max_features=None, \n",
    "                          vocabulary=None, \n",
    "                          binary=False)\n",
    "\n",
    "#Applying the vectorizer\n",
    "data_counts=counter.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In my younger and more vulnerable years my father gave me some advice that Ive been turning over in my mind ever since.', '\"Whenever you feel like criticizing any one,\" he told me, \"just remember that all the people in this world havent had the advantages that youve had.\"', \"He didn't say any more but weve always been unusually communicative in a reserved way, and I understood that he meant a great deal more than that.\", 'In consequence Im inclined to reserve all judgments, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores.', 'The abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person, and so it came about that in college', 'I was unjustly accused of being a politician, because I was privy to the secret griefs of wild, unknown men.', 'Most of the confidences were unsought--frequently I have feigned sleep, preoccupation, or a hostile levity when I realized by some unmistakable sign that an intimate revelation was quivering on the horizon--for the intimate revelations of young men or at least the terms in which they express them are usually plagiaristic and marred by obvious suppressions.', 'Reserving judgments is a matter of infinite hope.', 'I am still a little afraid of missing something if I forget that, as my father snobbishly suggested, and I snobbishly repeat a sense of the fundamental decencies is parcelled out unequally at birth.', 'And, after boasting this way of my tolerance, I come to the admission that it has a limit.', 'Conduct may be founded on the hard rock or the wet marshes but after a certain point I dont care what its founded on.', 'When I came back from the East last autumn I felt that I wanted the world to be in uniform and at a sort of moral attention forever; I wanted no more riotous excursions with privileged glimpses into the human heart.', 'Only Gatsby, the man who gives his name to this book, was exempt from my reaction--Gatsby who represented everything for which I have an unaffected scorn.', 'If personality is an unbroken series of successful gestures, then there was something gorgeous about him, some heightened sensitivity to the promises of life, as if he were related to one of those intricate machines that register earthquakes ten thousand miles away.', 'This responsiveness had nothing to do with that flabby impressionability which is dignified under the name of the \"creative temperament\"--it was an extraordinary gift for hope, a romantic readiness such as I have never found in any other person and which it is not likely I shall ever find again.', 'No--Gatsby turned out all right at the end; it is what preyed on Gatsby, what foul dust floated in the wake of his dreams that temporarily closed out my interest in the abortive sorrows and short-winded elations of men.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tf-idf matrix.\n",
    "counter = TfidfVectorizer(lowercase=False, \n",
    "                          stop_words=None,\n",
    "                          ngram_range=(1, 1), \n",
    "                          analyzer=u'word', \n",
    "                          max_df=.5, \n",
    "                          min_df=1,\n",
    "                          max_features=None, \n",
    "                          vocabulary=None, \n",
    "                          binary=False)\n",
    "\n",
    "#Applying the vectorizer\n",
    "data_counts=counter.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = counter.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And', 'Conduct', 'East', 'Gatsby', 'He', 'If', 'Im', 'In', 'Ive', 'Most', 'No', 'Only', 'Reserving', 'The', 'This', 'When', 'Whenever', 'abnormal', 'abortive', 'about', 'accused', 'admission', 'advantages', 'advice', 'afraid', 'after', 'again', 'all', 'also', 'always', 'am', 'an', 'any', 'appears', 'are', 'as', 'at', 'attach', 'attention', 'autumn', 'away', 'back', 'be', 'because', 'been', 'being', 'birth', 'boasting', 'book', 'bores', 'but', 'by', 'came', 'care', 'certain', 'closed', 'college', 'come', 'communicative', 'confidences', 'consequence', 'creative', 'criticizing', 'curious', 'deal', 'decencies', 'detect', 'didn', 'dignified', 'do', 'dont', 'dreams', 'dust', 'earthquakes', 'elations', 'end', 'ever', 'everything', 'excursions', 'exempt', 'express', 'extraordinary', 'father', 'feel', 'feigned', 'felt', 'few', 'find', 'flabby', 'floated', 'for', 'forever', 'forget', 'foul', 'found', 'founded', 'frequently', 'from', 'fundamental', 'gave', 'gestures', 'gift', 'gives', 'glimpses', 'gorgeous', 'great', 'griefs', 'habit', 'had', 'hard', 'has', 'have', 'havent', 'he', 'heart', 'heightened', 'him', 'his', 'hope', 'horizon', 'hostile', 'human', 'if', 'impressionability', 'in', 'inclined', 'infinite', 'interest', 'intimate', 'into', 'intricate', 'is', 'it', 'its', 'itself', 'judgments', 'just', 'last', 'least', 'levity', 'life', 'like', 'likely', 'limit', 'little', 'machines', 'made', 'man', 'many', 'marred', 'marshes', 'matter', 'may', 'me', 'meant', 'men', 'miles', 'mind', 'missing', 'moral', 'more', 'my', 'name', 'natures', 'never', 'no', 'normal', 'not', 'nothing', 'obvious', 'on', 'one', 'opened', 'or', 'other', 'out', 'over', 'parcelled', 'people', 'person', 'personality', 'plagiaristic', 'point', 'politician', 'preoccupation', 'preyed', 'privileged', 'privy', 'promises', 'quality', 'quick', 'quivering', 'reaction', 'readiness', 'realized', 'register', 'related', 'remember', 'repeat', 'represented', 'reserve', 'reserved', 'responsiveness', 'revelation', 'revelations', 'right', 'riotous', 'rock', 'romantic', 'say', 'scorn', 'secret', 'sense', 'sensitivity', 'series', 'shall', 'short', 'sign', 'since', 'sleep', 'snobbishly', 'so', 'some', 'something', 'sorrows', 'sort', 'still', 'successful', 'such', 'suggested', 'suppressions', 'temperament', 'temporarily', 'ten', 'terms', 'than', 'them', 'then', 'there', 'they', 'this', 'those', 'thousand', 'to', 'told', 'tolerance', 'turned', 'turning', 'unaffected', 'unbroken', 'under', 'understood', 'unequally', 'uniform', 'unjustly', 'unknown', 'unmistakable', 'unsought', 'unusually', 'up', 'usually', 'veteran', 'victim', 'vulnerable', 'wake', 'wanted', 'was', 'way', 'were', 'wet', 'weve', 'what', 'when', 'which', 'who', 'wild', 'winded', 'with', 'world', 'years', 'you', 'young', 'younger', 'youve']\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 284)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity\n",
    "\n",
    "So far, this is all (hopefully) familiar: We've done text parsing and the tf-idf calculation before.  We should now have sentences represented as vectors, with each word having a score based on how often it occurs in the sentence divided by how often it occurs in the whole text.\n",
    "\n",
    "Now let's calculate the similarity scores for the sentences and apply the TextRank algorithm.  Because TextRank is based on Google's PageRank algorithm, the function is called 'pagerank'.  The hyperparameters are the damping parameter ´alpha´ and the convergence parameter ´tol´."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.074946631856127058, 'This responsiveness had nothing to do with that flabby impressionability which is dignified under the name of the \"creative temperament\"--it was an extraordinary gift for hope, a romantic readiness such as I have never found in any other person and which it is not likely I shall ever find again.')\n"
     ]
    }
   ],
   "source": [
    "# Calculating similarity\n",
    "similarity = data_counts * data_counts.T\n",
    "\n",
    "# Identifying the sentence with the highest rank.\n",
    "nx_graph = nx.from_scipy_sparse_matrix(similarity)\n",
    "ranks=nx.pagerank(nx_graph, alpha=.85, tol=.00000001)\n",
    "\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(sentences)),\n",
    "                reverse=True)\n",
    "print(ranked[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since a lot of Gatsby is about the narrator acting as the observer of other peoples' sordid secrets, this seems pretty good.  Now, let's extract some keywords.\n",
    "\n",
    "# Keyword summarization\n",
    "\n",
    "1) Parse and tokenize text (already done).  \n",
    "2) Filter out stopwords, choose only nouns and adjectives.  \n",
    "3) Calculate the neighbors of words (we'll use a window of 4).  \n",
    "4) Run TextRank on the neighbor matrix.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words and punctuation, then getting a list of all unique words in the text\n",
    "gatsby_filt = [word for word in gatsby if word.is_stop==False and (word.pos_=='NOUN' or word.pos_=='ADJ')]\n",
    "words=set(gatsby_filt)\n",
    "\n",
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency=pd.DataFrame(columns=words,index=words,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(gatsby):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    if any([word == item for item in gatsby_filt]):\n",
    "        # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "        end=max(0,len(gatsby)-(len(gatsby)-(i+5)))\n",
    "        # The potential neighbors.\n",
    "        nextwords=gatsby[i+1:end]\n",
    "        # Filtering the neighbors to select only those in the word list\n",
    "        inset=[x in gatsby_filt for x in nextwords]\n",
    "        neighbors=[nextwords[i] for i in range(len(nextwords)) if inset[i]]\n",
    "        # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "        if neighbors:\n",
    "            adjacency.loc[word,neighbors]=adjacency.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.013370948308795436, hope), (0.012223431176324349, promises), (0.012223431176324349, exempt), (0.01214206885054891, glimpses), (0.011895137937387881, intimate)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Running TextRank\n",
    "#nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "nx_words = nx.from_numpy_matrix(adjacency.values)\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(words)),\n",
    "                reverse=True)\n",
    "print(ranked[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These results are less impressive.  'Hope', 'promises', and 'glimpses' certainly fit the elegiac, on-the-outside-looking-in tone of the book, but 'exempt' and 'world' are pretty generic.  TextRank may perform better on a larger text sample.\n",
    "\n",
    "# Drill\n",
    "\n",
    "It is also possible that keyword phrases will work better.  Modfiy the keyword extraction code to extract two-word phrases (digrams) rather than single words.  Then try it with trigrams.  You will probably want to broaden the window that defines 'neighbors.'  Try a few different modifications, and write up your observations in your notebook.  Discuss with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BIGRAMS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tf-idf matrix.\n",
    "counter_bigram = TfidfVectorizer(lowercase=False, \n",
    "                                  stop_words=None,\n",
    "                                  ngram_range=(2, 2), \n",
    "                                  analyzer=u'word', \n",
    "                                  max_df=.5, \n",
    "                                  min_df=1,\n",
    "                                  max_features=None, \n",
    "                                  vocabulary=None, \n",
    "                                  binary=False)\n",
    "\n",
    "#Applying the vectorizer\n",
    "data_counts_bigram = counter_bigram.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And after', 'Conduct may', 'East last', 'Gatsby the', 'Gatsby turned', 'Gatsby what', 'Gatsby who', 'He didn', 'If personality', 'Im inclined', 'In consequence', 'In my', 'Ive been', 'Most of', 'No Gatsby', 'Only Gatsby', 'Reserving judgments', 'The abnormal', 'This responsiveness', 'When came', 'Whenever you', 'abnormal mind', 'abortive sorrows', 'about him', 'about that', 'accused of', 'admission that', 'advantages that', 'advice that', 'afraid of', 'after boasting', 'after certain', 'all judgments', 'all right', 'all the', 'also made', 'always been', 'am still', 'an extraordinary', 'an intimate', 'an unaffected', 'an unbroken', 'and also', 'and at', 'and attach', 'and marred', 'and more', 'and short', 'and snobbishly', 'and so', 'and understood', 'and which', 'any more', 'any one', 'any other', 'appears in', 'are usually', 'as have', 'as if', 'as my', 'at birth', 'at least', 'at sort', 'at the', 'attach itself', 'attention forever', 'autumn felt', 'back from', 'be founded', 'be in', 'because was', 'been turning', 'been unusually', 'being politician', 'boasting this', 'book was', 'but after', 'but weve', 'by obvious', 'by some', 'came about', 'came back', 'care what', 'certain point', 'closed out', 'come to', 'communicative in', 'confidences were', 'consequence Im', 'creative temperament', 'criticizing any', 'curious natures', 'deal more', 'decencies is', 'detect and', 'didn say', 'dignified under', 'do with', 'dont care', 'dreams that', 'dust floated', 'earthquakes ten', 'elations of', 'end it', 'ever find', 'ever since', 'everything for', 'excursions with', 'exempt from', 'express them', 'extraordinary gift', 'father gave', 'father snobbishly', 'feel like', 'feigned sleep', 'felt that', 'few veteran', 'find again', 'flabby impressionability', 'floated in', 'for hope', 'for the', 'for which', 'forever wanted', 'forget that', 'foul dust', 'found in', 'founded on', 'frequently have', 'from my', 'from the', 'fundamental decencies', 'gave me', 'gestures then', 'gift for', 'gives his', 'glimpses into', 'gorgeous about', 'great deal', 'griefs of', 'habit that', 'had nothing', 'had the', 'hard rock', 'has limit', 'has opened', 'have an', 'have feigned', 'have never', 'havent had', 'he meant', 'he told', 'he were', 'heightened sensitivity', 'him some', 'his dreams', 'his name', 'hope romantic', 'horizon for', 'hostile levity', 'human heart', 'if forget', 'if he', 'impressionability which', 'in any', 'in college', 'in my', 'in normal', 'in reserved', 'in the', 'in this', 'in uniform', 'in which', 'inclined to', 'infinite hope', 'interest in', 'intimate revelation', 'intimate revelations', 'into the', 'intricate machines', 'is an', 'is dignified', 'is matter', 'is not', 'is parcelled', 'is quick', 'is what', 'it appears', 'it came', 'it has', 'it is', 'it was', 'its founded', 'itself to', 'judgments habit', 'judgments is', 'just remember', 'last autumn', 'least the', 'levity when', 'life as', 'like criticizing', 'likely shall', 'little afraid', 'machines that', 'made me', 'man who', 'many curious', 'marred by', 'marshes but', 'matter of', 'may be', 'me and', 'me just', 'me some', 'me the', 'meant great', 'men or', 'miles away', 'mind ever', 'mind is', 'missing something', 'moral attention', 'more but', 'more riotous', 'more than', 'more vulnerable', 'my father', 'my interest', 'my mind', 'my reaction', 'my tolerance', 'my younger', 'name of', 'name to', 'natures to', 'never found', 'no more', 'normal person', 'not few', 'not likely', 'nothing to', 'obvious suppressions', 'of being', 'of his', 'of infinite', 'of life', 'of men', 'of missing', 'of moral', 'of my', 'of not', 'of successful', 'of the', 'of those', 'of wild', 'of young', 'on Gatsby', 'on the', 'one he', 'one of', 'opened up', 'or at', 'or hostile', 'or the', 'other person', 'out all', 'out my', 'out unequally', 'over in', 'parcelled out', 'people in', 'person and', 'personality is', 'plagiaristic and', 'point dont', 'politician because', 'preoccupation or', 'preyed on', 'privileged glimpses', 'privy to', 'promises of', 'quality when', 'quick to', 'quivering on', 'reaction Gatsby', 'readiness such', 'realized by', 'register earthquakes', 'related to', 'remember that', 'repeat sense', 'represented everything', 'reserve all', 'reserved way', 'responsiveness had', 'revelation was', 'revelations of', 'right at', 'riotous excursions', 'rock or', 'romantic readiness', 'say any', 'secret griefs', 'sense of', 'sensitivity to', 'series of', 'shall ever', 'short winded', 'sign that', 'sleep preoccupation', 'snobbishly repeat', 'snobbishly suggested', 'so it', 'some advice', 'some heightened', 'some unmistakable', 'something gorgeous', 'something if', 'sorrows and', 'sort of', 'still little', 'successful gestures', 'such as', 'suggested and', 'temperament it', 'temporarily closed', 'ten thousand', 'terms in', 'than that', 'that Ive', 'that all', 'that an', 'that as', 'that flabby', 'that has', 'that he', 'that in', 'that it', 'that register', 'that temporarily', 'that wanted', 'that youve', 'the East', 'the abortive', 'the admission', 'the advantages', 'the confidences', 'the creative', 'the end', 'the fundamental', 'the hard', 'the horizon', 'the human', 'the intimate', 'the man', 'the name', 'the people', 'the promises', 'the secret', 'the terms', 'the victim', 'the wake', 'the wet', 'the world', 'them are', 'then there', 'there was', 'they express', 'this book', 'this quality', 'this way', 'this world', 'those intricate', 'thousand miles', 'to be', 'to detect', 'to do', 'to me', 'to one', 'to reserve', 'to the', 'to this', 'told me', 'tolerance come', 'turned out', 'turning over', 'unaffected scorn', 'unbroken series', 'under the', 'understood that', 'unequally at', 'uniform and', 'unjustly accused', 'unknown men', 'unmistakable sign', 'unsought frequently', 'unusually communicative', 'up many', 'usually plagiaristic', 'veteran bores', 'victim of', 'vulnerable years', 'wake of', 'wanted no', 'wanted the', 'was an', 'was exempt', 'was privy', 'was quivering', 'was something', 'was unjustly', 'way and', 'way of', 'were related', 'were unsought', 'wet marshes', 'weve always', 'what foul', 'what its', 'what preyed', 'when it', 'when realized', 'which have', 'which is', 'which it', 'which they', 'who gives', 'who represented', 'wild unknown', 'winded elations', 'with privileged', 'with that', 'world havent', 'world to', 'years my', 'you feel', 'young men', 'younger and', 'youve had']\n"
     ]
    }
   ],
   "source": [
    "print(counter_bigram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "gatsby_filt = [word.string.strip() for word in gatsby if word.is_stop==False and (word.pos_=='NOUN' or word.pos_=='ADJ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['younger',\n",
       " 'vulnerable',\n",
       " 'years',\n",
       " 'father',\n",
       " 'advice',\n",
       " 'mind',\n",
       " 'people',\n",
       " 'world',\n",
       " 'advantages',\n",
       " 'communicative',\n",
       " 'reserved',\n",
       " 'way',\n",
       " 'great',\n",
       " 'deal',\n",
       " 'consequence',\n",
       " 'inclined',\n",
       " 'judgments',\n",
       " 'habit',\n",
       " 'curious',\n",
       " 'natures',\n",
       " 'victim',\n",
       " 'veteran',\n",
       " 'bores',\n",
       " 'abnormal',\n",
       " 'mind',\n",
       " 'quick',\n",
       " 'quality',\n",
       " 'normal',\n",
       " 'person',\n",
       " 'college',\n",
       " 'politician',\n",
       " 'privy',\n",
       " 'secret',\n",
       " 'griefs',\n",
       " 'wild',\n",
       " 'unknown',\n",
       " 'men',\n",
       " 'Most',\n",
       " 'confidences',\n",
       " 'sleep',\n",
       " 'preoccupation',\n",
       " 'hostile',\n",
       " 'levity',\n",
       " 'unmistakable',\n",
       " 'sign',\n",
       " 'intimate',\n",
       " 'revelation',\n",
       " 'horizon',\n",
       " 'intimate',\n",
       " 'revelations',\n",
       " 'young',\n",
       " 'men',\n",
       " 'terms',\n",
       " 'plagiaristic',\n",
       " 'obvious',\n",
       " 'suppressions',\n",
       " 'Reserving',\n",
       " 'judgments',\n",
       " 'matter',\n",
       " 'infinite',\n",
       " 'hope',\n",
       " 'little',\n",
       " 'afraid',\n",
       " 'father',\n",
       " 'sense',\n",
       " 'fundamental',\n",
       " 'decencies',\n",
       " 'birth',\n",
       " 'way',\n",
       " 'tolerance',\n",
       " 'admission',\n",
       " 'limit',\n",
       " 'Conduct',\n",
       " 'hard',\n",
       " 'rock',\n",
       " 'wet',\n",
       " 'marshes',\n",
       " 'certain',\n",
       " 'point',\n",
       " 'autumn',\n",
       " 'world',\n",
       " 'uniform',\n",
       " 'sort',\n",
       " 'moral',\n",
       " 'attention',\n",
       " 'riotous',\n",
       " 'excursions',\n",
       " 'privileged',\n",
       " 'glimpses',\n",
       " 'human',\n",
       " 'heart',\n",
       " 'man',\n",
       " 'book',\n",
       " 'exempt',\n",
       " 'reaction',\n",
       " 'unaffected',\n",
       " 'scorn',\n",
       " 'personality',\n",
       " 'unbroken',\n",
       " 'series',\n",
       " 'successful',\n",
       " 'gestures',\n",
       " 'gorgeous',\n",
       " 'sensitivity',\n",
       " 'promises',\n",
       " 'life',\n",
       " 'intricate',\n",
       " 'machines',\n",
       " 'earthquakes',\n",
       " 'miles',\n",
       " 'responsiveness',\n",
       " 'flabby',\n",
       " 'impressionability',\n",
       " 'dignified',\n",
       " 'creative',\n",
       " 'temperament',\n",
       " 'extraordinary',\n",
       " 'gift',\n",
       " 'hope',\n",
       " 'romantic',\n",
       " 'readiness',\n",
       " 'person',\n",
       " 'likely',\n",
       " 'end',\n",
       " 'foul',\n",
       " 'dust',\n",
       " 'wake',\n",
       " 'dreams',\n",
       " 'interest',\n",
       " 'abortive',\n",
       " 'sorrows',\n",
       " 'elations',\n",
       " 'men']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = list(zip(gatsby_filt, gatsby_filt[1:]))\n",
    "trigrams = list(zip(gatsby_filt, gatsby_filt[1:], gatsby_filt[2:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('younger', 'vulnerable', 'years'), ('vulnerable', 'years', 'father'), ('years', 'father', 'advice'), ('father', 'advice', 'mind'), ('advice', 'mind', 'people'), ('mind', 'people', 'world'), ('people', 'world', 'advantages'), ('world', 'advantages', 'communicative'), ('advantages', 'communicative', 'reserved'), ('communicative', 'reserved', 'way'), ('reserved', 'way', 'great'), ('way', 'great', 'deal'), ('great', 'deal', 'consequence'), ('deal', 'consequence', 'inclined'), ('consequence', 'inclined', 'judgments'), ('inclined', 'judgments', 'habit'), ('judgments', 'habit', 'curious'), ('habit', 'curious', 'natures'), ('curious', 'natures', 'victim'), ('natures', 'victim', 'veteran'), ('victim', 'veteran', 'bores'), ('veteran', 'bores', 'abnormal'), ('bores', 'abnormal', 'mind'), ('abnormal', 'mind', 'quick'), ('mind', 'quick', 'quality'), ('quick', 'quality', 'normal'), ('quality', 'normal', 'person'), ('normal', 'person', 'college'), ('person', 'college', 'politician'), ('college', 'politician', 'privy'), ('politician', 'privy', 'secret'), ('privy', 'secret', 'griefs'), ('secret', 'griefs', 'wild'), ('griefs', 'wild', 'unknown'), ('wild', 'unknown', 'men'), ('unknown', 'men', 'Most'), ('men', 'Most', 'confidences'), ('Most', 'confidences', 'sleep'), ('confidences', 'sleep', 'preoccupation'), ('sleep', 'preoccupation', 'hostile'), ('preoccupation', 'hostile', 'levity'), ('hostile', 'levity', 'unmistakable'), ('levity', 'unmistakable', 'sign'), ('unmistakable', 'sign', 'intimate'), ('sign', 'intimate', 'revelation'), ('intimate', 'revelation', 'horizon'), ('revelation', 'horizon', 'intimate'), ('horizon', 'intimate', 'revelations'), ('intimate', 'revelations', 'young'), ('revelations', 'young', 'men'), ('young', 'men', 'terms'), ('men', 'terms', 'plagiaristic'), ('terms', 'plagiaristic', 'obvious'), ('plagiaristic', 'obvious', 'suppressions'), ('obvious', 'suppressions', 'Reserving'), ('suppressions', 'Reserving', 'judgments'), ('Reserving', 'judgments', 'matter'), ('judgments', 'matter', 'infinite'), ('matter', 'infinite', 'hope'), ('infinite', 'hope', 'little'), ('hope', 'little', 'afraid'), ('little', 'afraid', 'father'), ('afraid', 'father', 'sense'), ('father', 'sense', 'fundamental'), ('sense', 'fundamental', 'decencies'), ('fundamental', 'decencies', 'birth'), ('decencies', 'birth', 'way'), ('birth', 'way', 'tolerance'), ('way', 'tolerance', 'admission'), ('tolerance', 'admission', 'limit'), ('admission', 'limit', 'Conduct'), ('limit', 'Conduct', 'hard'), ('Conduct', 'hard', 'rock'), ('hard', 'rock', 'wet'), ('rock', 'wet', 'marshes'), ('wet', 'marshes', 'certain'), ('marshes', 'certain', 'point'), ('certain', 'point', 'autumn'), ('point', 'autumn', 'world'), ('autumn', 'world', 'uniform'), ('world', 'uniform', 'sort'), ('uniform', 'sort', 'moral'), ('sort', 'moral', 'attention'), ('moral', 'attention', 'riotous'), ('attention', 'riotous', 'excursions'), ('riotous', 'excursions', 'privileged'), ('excursions', 'privileged', 'glimpses'), ('privileged', 'glimpses', 'human'), ('glimpses', 'human', 'heart'), ('human', 'heart', 'man'), ('heart', 'man', 'book'), ('man', 'book', 'exempt'), ('book', 'exempt', 'reaction'), ('exempt', 'reaction', 'unaffected'), ('reaction', 'unaffected', 'scorn'), ('unaffected', 'scorn', 'personality'), ('scorn', 'personality', 'unbroken'), ('personality', 'unbroken', 'series'), ('unbroken', 'series', 'successful'), ('series', 'successful', 'gestures'), ('successful', 'gestures', 'gorgeous'), ('gestures', 'gorgeous', 'sensitivity'), ('gorgeous', 'sensitivity', 'promises'), ('sensitivity', 'promises', 'life'), ('promises', 'life', 'intricate'), ('life', 'intricate', 'machines'), ('intricate', 'machines', 'earthquakes'), ('machines', 'earthquakes', 'miles'), ('earthquakes', 'miles', 'responsiveness'), ('miles', 'responsiveness', 'flabby'), ('responsiveness', 'flabby', 'impressionability'), ('flabby', 'impressionability', 'dignified'), ('impressionability', 'dignified', 'creative'), ('dignified', 'creative', 'temperament'), ('creative', 'temperament', 'extraordinary'), ('temperament', 'extraordinary', 'gift'), ('extraordinary', 'gift', 'hope'), ('gift', 'hope', 'romantic'), ('hope', 'romantic', 'readiness'), ('romantic', 'readiness', 'person'), ('readiness', 'person', 'likely'), ('person', 'likely', 'end'), ('likely', 'end', 'foul'), ('end', 'foul', 'dust'), ('foul', 'dust', 'wake'), ('dust', 'wake', 'dreams'), ('wake', 'dreams', 'interest'), ('dreams', 'interest', 'abortive'), ('interest', 'abortive', 'sorrows'), ('abortive', 'sorrows', 'elations'), ('sorrows', 'elations', 'men')]\n"
     ]
    }
   ],
   "source": [
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = [' '.join(tup) for tup  in bigrams]\n",
    "trigrams = [' '.join(tup) for tup in trigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['younger vulnerable years', 'vulnerable years father', 'years father advice', 'father advice mind', 'advice mind people', 'mind people world', 'people world advantages', 'world advantages communicative', 'advantages communicative reserved', 'communicative reserved way', 'reserved way great', 'way great deal', 'great deal consequence', 'deal consequence inclined', 'consequence inclined judgments', 'inclined judgments habit', 'judgments habit curious', 'habit curious natures', 'curious natures victim', 'natures victim veteran', 'victim veteran bores', 'veteran bores abnormal', 'bores abnormal mind', 'abnormal mind quick', 'mind quick quality', 'quick quality normal', 'quality normal person', 'normal person college', 'person college politician', 'college politician privy', 'politician privy secret', 'privy secret griefs', 'secret griefs wild', 'griefs wild unknown', 'wild unknown men', 'unknown men Most', 'men Most confidences', 'Most confidences sleep', 'confidences sleep preoccupation', 'sleep preoccupation hostile', 'preoccupation hostile levity', 'hostile levity unmistakable', 'levity unmistakable sign', 'unmistakable sign intimate', 'sign intimate revelation', 'intimate revelation horizon', 'revelation horizon intimate', 'horizon intimate revelations', 'intimate revelations young', 'revelations young men', 'young men terms', 'men terms plagiaristic', 'terms plagiaristic obvious', 'plagiaristic obvious suppressions', 'obvious suppressions Reserving', 'suppressions Reserving judgments', 'Reserving judgments matter', 'judgments matter infinite', 'matter infinite hope', 'infinite hope little', 'hope little afraid', 'little afraid father', 'afraid father sense', 'father sense fundamental', 'sense fundamental decencies', 'fundamental decencies birth', 'decencies birth way', 'birth way tolerance', 'way tolerance admission', 'tolerance admission limit', 'admission limit Conduct', 'limit Conduct hard', 'Conduct hard rock', 'hard rock wet', 'rock wet marshes', 'wet marshes certain', 'marshes certain point', 'certain point autumn', 'point autumn world', 'autumn world uniform', 'world uniform sort', 'uniform sort moral', 'sort moral attention', 'moral attention riotous', 'attention riotous excursions', 'riotous excursions privileged', 'excursions privileged glimpses', 'privileged glimpses human', 'glimpses human heart', 'human heart man', 'heart man book', 'man book exempt', 'book exempt reaction', 'exempt reaction unaffected', 'reaction unaffected scorn', 'unaffected scorn personality', 'scorn personality unbroken', 'personality unbroken series', 'unbroken series successful', 'series successful gestures', 'successful gestures gorgeous', 'gestures gorgeous sensitivity', 'gorgeous sensitivity promises', 'sensitivity promises life', 'promises life intricate', 'life intricate machines', 'intricate machines earthquakes', 'machines earthquakes miles', 'earthquakes miles responsiveness', 'miles responsiveness flabby', 'responsiveness flabby impressionability', 'flabby impressionability dignified', 'impressionability dignified creative', 'dignified creative temperament', 'creative temperament extraordinary', 'temperament extraordinary gift', 'extraordinary gift hope', 'gift hope romantic', 'hope romantic readiness', 'romantic readiness person', 'readiness person likely', 'person likely end', 'likely end foul', 'end foul dust', 'foul dust wake', 'dust wake dreams', 'wake dreams interest', 'dreams interest abortive', 'interest abortive sorrows', 'abortive sorrows elations', 'sorrows elations men']\n"
     ]
    }
   ],
   "source": [
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency_bigram=pd.DataFrame(columns=bigrams,index=bigrams,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(bigrams):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "    end=max(0,len(bigrams)-(len(bigrams)-(i+5)))\n",
    "    # The potential neighbors.\n",
    "    nextwords=bigrams[i+1:end]\n",
    "    # Filtering the neighbors to select only those in the word list\n",
    "    #inset=[x in gatsby_filt for x in nextwords]\n",
    "    neighbors=[nextwords[i] for i in range(len(nextwords))] # if inset[i]] \n",
    "    # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "    if neighbors:\n",
    "        adjacency_bigram.loc[word,neighbors]=adjacency_bigram.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.008478571504987353, 'r e s e r v e d   w a y'), (0.008478571504987353, 'p e r s o n   l i k e l y'), (0.008396088482342145, 'w a y   g r e a t'), (0.008396088482342145, 'r e a d i n e s s   p e r s o n'), (0.008322012406773167, 'g r e a t   d e a l')]\n"
     ]
    }
   ],
   "source": [
    "# Running TextRank\n",
    "#nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "nx_words = nx.from_numpy_matrix(adjacency_bigram.values)\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(bigrams)),\n",
    "                reverse=True)\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Increasing Neighborhood size to 7\n",
    "\n",
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency_bigram=pd.DataFrame(columns=bigrams,index=bigrams,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(bigrams):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "    end=max(0,len(bigrams)-(len(bigrams)-(i+8)))\n",
    "    # The potential neighbors.\n",
    "    nextwords=bigrams[i+1:end]\n",
    "    # Filtering the neighbors to select only those in the word list\n",
    "    #inset=[x in gatsby_filt for x in nextwords]\n",
    "    neighbors=[nextwords[i] for i in range(len(nextwords))] # if inset[i]] \n",
    "    # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "    if neighbors:\n",
    "        adjacency_bigram.loc[word,neighbors]=adjacency_bigram.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.00849776192675846, 'f o u l   d u s t'), (0.008497761926758458, 'w o r l d   a d v a n t a g e s'), (0.00838308473138196, 'e n d   f o u l'), (0.00838308473138196, 'a d v a n t a g e s   c o m m u n i c a t i v e'), (0.008284113942061676, 'l i k e l y   e n d')]\n"
     ]
    }
   ],
   "source": [
    "# Running TextRank\n",
    "#nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "nx_words = nx.from_numpy_matrix(adjacency_bigram.values)\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(bigrams)),\n",
    "                reverse=True)\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Increasing Neighborhood size to 10\n",
    "\n",
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency_bigram=pd.DataFrame(columns=bigrams,index=bigrams,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(bigrams):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "    end=max(0,len(bigrams)-(len(bigrams)-(i+11)))\n",
    "    # The potential neighbors.\n",
    "    nextwords=bigrams[i+1:end]\n",
    "    # Filtering the neighbors to select only those in the word list\n",
    "    #inset=[x in gatsby_filt for x in nextwords]\n",
    "    neighbors=[nextwords[i] for i in range(len(nextwords))] # if inset[i]] \n",
    "    # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "    if neighbors:\n",
    "        adjacency_bigram.loc[word,neighbors]=adjacency_bigram.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.008478571504987353, 'r e s e r v e d   w a y'), (0.008478571504987353, 'p e r s o n   l i k e l y'), (0.008396088482342145, 'w a y   g r e a t'), (0.008396088482342145, 'r e a d i n e s s   p e r s o n'), (0.008322012406773167, 'g r e a t   d e a l')]\n"
     ]
    }
   ],
   "source": [
    "# Running TextRank\n",
    "#nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "nx_words = nx.from_numpy_matrix(adjacency_bigram.values)\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(bigrams)),\n",
    "                reverse=True)\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Results for Bigrams ###\n",
    "\n",
    "* We extract \"reserved way\", \"person likely\", \"way great\", \"readiness person\" and \"great deal\" for a neighborhood size of 4.\n",
    "\n",
    "* We extract \"foul dust\", \"world advantages\", \"end foul\", \"advantages communicative\" and \"likely end\" for a size of 7.\n",
    "\n",
    "* For a neighborhood size of 10, we extract the bigrams \"reserved way\", \"person likely\", \"way great\", \"readiness person\" and \"great deal\"\n",
    "\n",
    "* The bigrams for sizes of 4 and 10 repeat.  Many of them seem to have some relationship with a book like Gatsby.\n",
    "\n",
    "* Best examples are \"way great\" and \"great deal\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIGRAMS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency_trigram=pd.DataFrame(columns=trigrams,index=trigrams,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(trigrams):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "    end=max(0,len(trigrams)-(len(trigrams)-(i+5)))\n",
    "    # The potential neighbors.\n",
    "    nextwords=trigrams[i+1:end]\n",
    "    # Filtering the neighbors to select only those in the word list\n",
    "    #inset=[x in gatsby_filt for x in nextwords]\n",
    "    neighbors=[nextwords[i] for i in range(len(nextwords))] # if inset[i]] \n",
    "    # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "    if neighbors:\n",
    "        adjacency_trigram.loc[word,neighbors]=adjacency_trigram.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.008608224436651105, 'wake dreams interest'), (0.008608224436651105, 'advice mind people'), (0.008418552148932803, 'mind people world'), (0.008418552148932803, 'dust wake dreams'), (0.008268498103417074, 'foul dust wake')]\n"
     ]
    }
   ],
   "source": [
    "# Running TextRank\n",
    "#nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "nx_words = nx.from_numpy_matrix(adjacency_trigram.values)\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(trigrams)),\n",
    "                reverse=True)\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Creating a grid indicating whether words are within 7 places of the target word\n",
    "adjacency_trigram=pd.DataFrame(columns=trigrams,index=trigrams,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(trigrams):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "    end=max(0,len(trigrams)-(len(trigrams)-(i+8)))\n",
    "    # The potential neighbors.\n",
    "    nextwords=trigrams[i+1:end]\n",
    "    # Filtering the neighbors to select only those in the word list\n",
    "    #inset=[x in gatsby_filt for x in nextwords]\n",
    "    neighbors=[nextwords[i] for i in range(len(nextwords))] # if inset[i]] \n",
    "    # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "    if neighbors:\n",
    "        adjacency_trigram.loc[word,neighbors]=adjacency_trigram.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.008562630346707433, 'world advantages communicative'), (0.008562630346707432, 'end foul dust'), (0.008447077754373141, 'likely end foul'), (0.008447077754373141, 'advantages communicative reserved'), (0.008347351464644144, 'person likely end')]\n"
     ]
    }
   ],
   "source": [
    "# Running TextRank\n",
    "#nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "nx_words = nx.from_numpy_matrix(adjacency_trigram.values)\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(trigrams)),\n",
    "                reverse=True)\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Creating a grid indicating whether words are within 10 places of the target word\n",
    "adjacency_trigram=pd.DataFrame(columns=trigrams,index=trigrams,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(trigrams):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "    end=max(0,len(trigrams)-(len(trigrams)-(i+11)))\n",
    "    # The potential neighbors.\n",
    "    nextwords=trigrams[i+1:end]\n",
    "    # Filtering the neighbors to select only those in the word list\n",
    "    #inset=[x in gatsby_filt for x in nextwords]\n",
    "    neighbors=[nextwords[i] for i in range(len(nextwords))] # if inset[i]] \n",
    "    # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "    if neighbors:\n",
    "        adjacency_trigram.loc[word,neighbors]=adjacency_trigram.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.008543296283550108, 'reserved way great'), (0.008543296283550108, 'readiness person likely'), (0.008460183839056497, 'way great deal'), (0.008460183839056497, 'romantic readiness person'), (0.008385542544465694, 'hope romantic readiness')]\n"
     ]
    }
   ],
   "source": [
    "# Running TextRank\n",
    "#nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "nx_words = nx.from_numpy_matrix(adjacency_trigram.values)\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(trigrams)),\n",
    "                reverse=True)\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Results ###\n",
    "\n",
    "* We finally see some truly interesting phrases\n",
    "\n",
    "* The best appear to be \"reserved way great\", \"hope romantic readiness\", and \"way great deal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
